# SIFT算子 & SURF算子

## SIFT算子

### 解释

`Scale Invariant Feature Transform` 尺度不变特征变换。SIFT特征 对于旋转、尺度缩放、亮度变换等保持不变性。

通过图像的模糊程度来模拟人在距离物体由远到近时物体在视网膜上成像过程，距离物体越近其尺寸越大图像也越模糊，这就是高斯尺度空间，使用不同的参数模糊图像（分辨率不变），是尺度空间的另一种表现形式。

图像和高斯函数进行卷积运算能够对图像进行模糊，使用不同的“高斯核”可得到不同模糊程度的图像。一副图像其高斯尺度空间可由其和不同的高斯卷积得到：
$$
L(x,y,σ) = G(x,y,σ)*I(x,y)
$$
其中G(x ,y, σ) 是高斯核函数
$$
G(x,y,σ)=1/(2πσ^2)e^{(x^2+y^2)/2σ^2}
$$
σ称为尺度空间因子，它是高斯正态分布的标准差，反映了图像被模糊的程度，其值越大图像越模糊，对应的尺度也就越大。L(x,y,σ)代表着图像的高斯尺度空间。

**构建尺度空间的目的是为了检测出在不同的尺度下都存在的特征点，而检测特征点较好的算子是![\Delta ^{2}G](https://private.codecogs.com/gif.latex?%5CDelta%20%5E%7B2%7DG)(高斯拉普拉斯,LoG）,**

![img](https://img-blog.csdnimg.cn/20190507163335627.png)

使用LoG虽然能较好的检测到图像中的特征点，但是其运算量过大，通常可使用**DoG（差分高斯，Difference of Gaussina）**来近似计算LoG[Marr and Hidreth]。

![img](https://img-blog.csdnimg.cn/20190507163702807.png)

**高斯金字塔构建成功后，将每一组相邻的两层相减就可以得到DoG金字塔.**



SIFT特征以其对旋转、尺度缩放、亮度等保持不变性，是一种非常稳定的局部特征，在图像处理和计算机视觉领域有着很重要的作用，其本身也是非常复杂的，下面对其计算过程做一个粗略总结。

1. DoG尺度空间的极值检测： 首先是构造DoG尺度空间，在SIFT中使用不同参数的高斯模糊来表示不同的尺度空间。而构造尺度空间是为了检测在不同尺度下都存在的特征点，特征点的检测比较常用的方法是Δ2G（高斯拉普拉斯LoG），但是LoG的运算量是比较大的，Marr和Hidreth曾指出，可以使用DoG（差分高斯）来近似计算LoG，所以在DoG的尺度空间下检测极值点。
2. 删除不稳定的极值点：主要删除两类：低对比度的极值点以及不稳定的边缘响应点。
3. 确定特征点的主方向：以特征点的为中心、以3×1.5σ为半径的领域内计算各个像素点的梯度的幅角和幅值，然后使用直方图对梯度的幅角进行统计。直方图的横轴是梯度的方向，纵轴为梯度方向对应梯度幅值的累加值，直方图中最高峰所对应的方向即为特征点的方向。
4. 生成特征点的描述子： 首先将坐标轴旋转为特征点的方向，以特征点为中心的16×16的窗口的像素的梯度幅值和方向，将窗口内的像素分成16块，每块是其像素内8个方向的直方图统计，共可形成128维的特征向量

#### 空间极值点检测

为了寻找DOG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度空间域的相邻点大或者小。

![img](https://img-blog.csdn.net/20160918211309513)

在二维图像空间，中心点与它3\*3邻域内的8个点做比较，在同一组内的尺度空间上，中心点和上下相邻的两层图像的2*9个点作比较，一共26个点，如此可以保证检测到的关键点在尺度空间和二维图像空间上都是局部极值点。

#### 稳定关键点的精确定位

DOG值对噪声和边缘比较敏感，所以在第2步的尺度空间中检测到的局部极值点还要经过进一步的筛选，去除不稳定和错误检测出的极值点，另一点就是在构建高斯金字塔过程中采用了下采样的图像，在下采样图像中提取的极值点对应在原始图像中的确切位置，也是要在本步骤中解决的问题。

#### 稳定关键点方向信息分配

稳定的极值点是在不同尺度空间下提取的，这保证了关键点的尺度不变性。为关键点分配方向信息所要解决的问题是使得**关键点对图像角度和旋转具有不变性**。方向的分配是通过求每个极值点的梯度来实现的。

对于任一关键点，其梯度幅值表述为：

![img](https://img-blog.csdn.net/20160918212038619)

梯度方向为：

![img](https://img-blog.csdn.net/20160918212042391)

**分配给关键点的方向并不直接是关键点的梯度方向，而是按照一种梯度方向直方图的方式给出的。**

具体的方法是：计算以关键点为中心的邻域内所有点的梯度方向，当然梯度方向一定是在0~360°范围内，对这些梯度方向归一化到36个方向内，**每个方向代表了10°的范围**。然后累计落到每个方向内的关键点个数，以此生成梯度方向直方图。

![img](https://img-blog.csdn.net/20160918212445002)

**将梯度方向直方图中纵坐标最大的项代表的方向分配给当前关键点作为主方向，若在梯度直方图中存在一个相当于主峰值80%能量的峰值，则将这个方向认为是关键点的辅方向**。辅方向的设计可以增强匹配的鲁棒性，Lowe指出，大概有15%的关键点具有辅方向，**而恰恰是这15%的关键点对稳定匹配起到关键作用。**

#### 关键点描述

对关键点的描述是后续实现匹配的关键步骤，描述其实就是一种以数学方式定义关键的过程。描述子不但包含关键点，也包括关键点周围对其有贡献的邻域点。

特征描述符的生成大致有三个步骤：

1. 校正旋转主方向，确保旋转不变性。
2. 生成描述子，最终形成一个128维的特征向量
3. 归一化处理，将特征向量长度进行归一化处理，进一步去除光照的影响。

为了保证特征矢量的旋转不变性，要以特征点为中心附近邻域内将坐标轴旋转θ（特征点的主方向）角度，即将坐标轴旋转为特征点的主方向。旋转后邻域内像素的新坐标为

![img](https://img-blog.csdnimg.cn/20190507165240615.png)



旋转后以主方向为中心取 8 * 8 的窗口，左图的中央为当前关键点的位置，每个小格代表为关键点邻域所在尺度空间的一个像素，求取每个像素的梯度幅值与梯度方向，箭头方向代表该像素的梯度方向，长度代表梯度幅值，然后利用高斯窗口对其进行加权运算。最后在每个4×4的小块上绘制8个方向的梯度直方图

![img](https://img-blog.csdn.net/20160918213353043)

实验结果表明：对每个关键点，采用4*4*8共128维向量的描述子进项关键点表征，综合效果最佳

#### 特征点的匹配

特征点的匹配是通过计算两组特征点的128维的关键点的欧式距离实现的。欧式距离越小，则相似度越高，当欧式距离小于设定的阈值时，可以判定为匹配成功

### 图像金字塔

一种以多分辨率来解释图像的结构，通过对原始图像进行多尺度像素采样的方式，生成N个不同分辨率的图像。把具有最高级别分辨率的图像放在底部，以金字塔形状排列，往上是一系列像素（尺寸）逐渐降低的图像，一直到金字塔的顶部只包含一个像素点的图像，这就构成了传统意义上的图像金字塔。

获得图像金字塔一般包括二个步骤：

1. 利用低通滤波器平滑图像 

2. 对平滑图像进行抽样（采样）

有两种采样方式——**上采样**（分辨率逐级升高，图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的元素）和 **下采样**（分辨率逐级降低，对于一副图像I尺寸为M*N，对起进行s倍下采样，即得到（M/s）*（N/s）尺寸的分辨率图像，当然，s应该是M和N的公约数才可以，如果考虑是矩阵形式的图像，就是把原始图像s*s窗口内的图像编程一个像素，这个像素点的值就是窗口内所有像素的均值或者最大值）

上采样：

![img](https://img-blog.csdn.net/20160917203356768)

下采样

![img](https://img-blog.csdn.net/20160917203457519)

### 高斯金字塔

高斯金字塔式在Sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是有很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval）。

构建过程：

1. 先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（其实就是高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层，高斯卷积函数为：

![img](https://img-blog.csdn.net/20160917205739118)

其中对于参数σ，在Sift算子中取的是固定值1.6。

2. 将σ乘以一个比例系数k,等到一个新的平滑因子σ=k*σ，用它来平滑第1组第2层图像，结果图像作为第3层。

3. 如此这般重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：0，σ，kσ，k^2σ,k^3σ……k^(L-2)σ。
4. 将第1组倒数第三层图像作比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像做平滑因子为σ的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：0，σ，kσ，k^2σ,k^3σ……k^(L-2)σ。但是在尺寸方面第2组是第1组图像的一半。

这样反复执行，就可以得到一共O组，每组L层，共计O*L个图像，这些图像一起就构成了高斯金字塔，结构

![img](https://img-blog.csdn.net/20160917212318336)

在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子σ是前一层图像平滑因子的k倍；

在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半；

### 尺度空间

图像的尺度空间解决的问题是如何对图像在所有尺度下描述的问题。

在高斯金字塔中一共生成O组L层不同尺度的图像，这两个量合起来（O，L）就构成了高斯金字塔的尺度空间，也就是说以高斯金字塔的组O作为二维坐标系的一个坐标，不同层L作为另一个坐标，则给定的一组坐标（O,L）就可以唯一确定高斯金字塔中的一幅图像。

![img](https://img-blog.csdn.net/20160917222117365)

### DOG金字塔

差分金字塔，DOG（Difference of Gaussian）金字塔是在高斯金字塔的基础上构建起来的，其实生成高斯金字塔的目的就是为了构建DOG金字塔。

DOG金字塔的第1组第1层是由高斯金字塔的第1组第2层减第1组第1层得到的。以此类推，逐组逐层生成每一个差分图像，所有差分图像构成差分金字塔。概括为DOG金字塔的第o组第l层图像是有高斯金字塔的第o组第l+![img](https://img-blog.csdn.net/20160917223500317)1层减第o组第l层得到的。

每一组在层数上，DOG金字塔比高斯金字塔少一层。下边**对这些DOG图像进行归一化，可有很明显的看到差分图像所蕴含的特征**，并且有一些特征是在不同模糊程度、不同尺度下都存在的，这些特征正是Sift所要提取的“稳定”特征

## SURF算法

对于一个特征点提取算法，为了实现方向旋转和尺度变换的的不变性，输出结果应当包括三个方面的内容，特征点的位置信息，方向信息，特征描述。这里的位置信息包括特征点在图像上的位置x，y以及特征点所在的尺度。

### 特征点定位

在关键点的定位上，SURF使用积分图和Boxfilter计算hessian矩阵，通过比较hessian矩阵行列式的大小来选择特征点的位置和尺度,而不是SIFT所使用的DOG算子，金字塔构建时通过改变boxfilter的尺寸和滤波器的方差来实现不同的尺度图像的获取。

#### 积分图计算

#### 主要目的是为了获得某一个区域的像素和 

![[公式]](https://www.zhihu.com/equation?tex=I_%7B%5CSigma%7D%28x%29%3D%5Csum_%7Bi%3D0%7D%5E%7Bi%5Cleq+x%7D%5Csum_%7Bj%3D0%7D%5E%7Bj%5Cleq+y%7D%7BI%28i%2Cj%29%7D)

![img](https://pic4.zhimg.com/80/v2-dd871d60824aa6e028b9589e229af6df_720w.jpg)

如上图，计算 ![[公式]](https://www.zhihu.com/equation?tex=%5CSigma) 区域内的像素和只需要计算三次加减法。

图像金字塔构建时，需要用不同的 σ 的高斯模板和原图卷积然后计算每个点处的hessian 值，

在尺度 σ 下，点 x = (X, Y) 处的 Hessian 的值为

![[公式]](https://www.zhihu.com/equation?tex=H%28%5Cbm%7Bx%7D%2C%5Csigma%29%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+++L_%7Bxx%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29%26+L_%7Bxy%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29+%5C%5C+L_%7Byx%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29%26+L_%7Byy%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29+%5C%5C++%5Cend%7Barray%7D++%5Cright+%5D)

其中 ![[公式]](https://www.zhihu.com/equation?tex=L_%7Bxx%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29) 是 ![[公式]](https://www.zhihu.com/equation?tex=%5Cbm%7Bx%7D+) 处图像和二阶级高斯模板 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%5E%7B2%7D%7D%7B%5Cpartial+x%5E2%7Dg%28%5Csigma%29) 的卷积， ![[公式]](https://www.zhihu.com/equation?tex=L_%7Bxy%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29) 和 ![[公式]](https://www.zhihu.com/equation?tex=L_%7Byy%7D%28%5Cbm%7Bx%7D%2C%5Csigma%29) 同理。

然而实际计算时，我们并不会真的用 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%5E%7B2%7D%7D%7B%5Cpartial+x%5E2%7Dg%28%5Csigma%29) 和图像卷积，而是使用盒式滤波器Boxfilter近似。

![img](https://pic1.zhimg.com/80/v2-cc20bb16a47f6a780ce96e8af3c9425c_720w.jpg)

使用盒式滤波器卷积时，可以查找积分图中的元素来加快计算。

每个像素的Hessian矩阵行列式的近似值：

![[公式]](https://www.zhihu.com/equation?tex=det%28H%29%3DD_%7Bxx%7D%2AD_%7Byy%7D-w%2AD_%7Bxy%7D%5E2)

在 ![[公式]](https://www.zhihu.com/equation?tex=D_%7Bxy%7D) 上乘了一个加权系数0.9，目的是为了平衡因使用盒式滤波器近似所带来的误差。

#### Scale space representation

同Sift一样，Surf的尺度空间也是由O组L层组成，不同的是，Sift中下一组图像的尺寸是上一组的一半，同一组间图像尺寸一样，但是所使用的高斯模糊系数逐渐增大；而在Surf中，不同组间图像的尺寸都是一致的，但不同组间使用的盒式滤波器的模板尺寸逐渐增大，同一组间不同层间使用相同尺寸的滤波器，但是滤波器的模糊系数逐渐增大。

在sift中，通过不断地减小图像尺寸来模拟远近变化，而SURF是通过改变fiter的尺寸来实现不同尺度的获得，不会因为filter尺寸的变大而使得计算量变大，因为在卷积是仅仅是查找积分图中的四个角处的数值，所有层的计算代价都是相同的。

#### 关键点定位

特征点的定位过程Surf和Sift保持一致，将经过Hessian矩阵处理的每个像素点与二维图像空间和尺度空间邻域内的26个点进行比较，初步定位出关键点，再经过滤除能量比较弱的关键点以及错误定位的关键点，筛选出最终的稳定的特征点。

#### 方向分配

Sift特征点方向分配是采用在特征点邻域内统计其梯度直方图，而在Surf中，采用的是统计特征点圆形邻域内的haar小波特征。

在特征点的圆形邻域内，统计60度扇形内所有点的水平、垂直haar小波特征总和，然后扇形以一定间隔进行旋转并再次统计该区域内haar小波特征值之后，最后将值最大的那个扇形的方向作为该特征点的主方向。

##### **统计60度扇形内所有点的水平、垂直haar小波特征总和**

其具体方法是首先在特征点位置画一个直径为6s的圆形，s为尺度。分别计算这个圆中的每个以s*s为间隔取样的点处的haarX和haarY特征，同时计算每个点的特征方向  ![[公式]](https://www.zhihu.com/equation?tex=+%5Ctheta_i%3D%5Carctan%28%5Cfrac%7BhaarY%7D%7BhaarX%7D%29) ，在一个60度的扇形中统计落在扇形角度范围内的点的harrX和HarrY各自之和sumX和sumY，该扇形以每次15度的精度绕中心旋转，选取使得sum的模长最大的扇形方向为该特征点的方向，其中，harr小波特征的计算需要再次用到积分图。

![img](https://pic1.zhimg.com/80/v2-8fbb8792526e1210b1bb7a57ec243a48_720w.jpg)

##### 补充小波变换(Haar变换)

例如我们有一个一维的图像[2,4,6,8,10,12,14,16].

求均值：我们求相邻像素的均值[3,7,11,15]。这个新的图像分辨率就成了原来的一半(8/2=4)。

求差值。上面的均值我们存储了图像的整体信息。但是很多细节信息我们丢掉了，所以我们同时要记录图像的细节信息，这样在重构时能够恢复图像的全部信息。下面是求第m个差值的公式：
$$
b[m]=(a[2m]−a[2m+1])/2
$$
此时上面两步形成了第一次分解的结果[3,7,11,15,-1,-1,-1,-1]。包含了图像的整体信息和细节信息。接下来的分解我们重复1,2步，将整体信息再次进行分解，得到了二级分解结果[5，13，-2，-2].同样的，前面的[5,13]是整体信息，后面的[-2,-2]是细节信息。

#### 特征描述

描述符计算，分为U-SURF和SURF,U-SURF即Upright，不计算特征点的方向信息，所有点统一认为方向向上，只需要将设为0即可。USURF虽然舍弃了方向信息，但对于轻微的角度变化仍有一定的鲁棒性。首先根据方向信息，以特征点的位置为中心转动20s*20s的方框和主方向重合，将该方框划分为4x4的subregion,每个subregien为5sx5s,对每一个subregion的每个点计算harrX,harrY，|harrX|,|harrY|，同时按照二维高斯函数加权求和得到长度为4的向量，因此对于16个区域总共能够得到64维的向量，这里有一点还需要注意:在将16个区域的4个特征组合成64维向量时，还需要需要对每一个区域的特征和高斯模板卷积，最后进行归一化处理以获得光照不变性。